# TA Topic Assignment for ML Course Materials Review

## 📋 Assignment Overview
Each TA is responsible for thoroughly reviewing **slides, notebooks, and tutorials** for their assigned topic(s). Use the `TA_BUG_REPORT_GUIDE.md` for detailed review criteria.

---

## 👥 TA Topic Assignments

### **T1 - Linear Regression** 📈
**Materials to Review:**
- 📊 `supervised/slides/linear-regression.tex`
- 📓 Notebooks: Linear regression implementations and examples
- 📖 `supervised/tutorials/linear-regression.tex`

**Focus Areas:**
- Mathematical notation consistency (θ → \vtheta, X → \mX, Y → \vy)
- Normal equation derivations and implementations
- Regularization content (Ridge/Lasso) - newly added
- Geometric interpretations and visualizations

---

### **T2 - Logistic Regression** 📊
**Materials to Review:**
- 📊 `supervised/slides/logistic-regression.tex`
- 📓 Notebooks: Sigmoid function, gradient descent implementations
- 📖 `supervised/tutorials/logistic-regression.tex`

**Focus Areas:**
- Sigmoid function properties and derivations
- Maximum likelihood estimation explanations
- Cross-entropy loss function clarity
- Binary vs multiclass extensions

---

### **T3 - Decision Trees** 🌳
**Materials to Review:**
- 📊 `supervised/slides/decision-trees.tex`
- 📓 Notebooks: Tree construction, entropy calculations
- 📖 `supervised/tutorials/` (decision trees related)

**Focus Areas:**
- Entropy and information gain calculations
- Tree construction algorithms
- Pruning techniques - recently enhanced
- Overfitting/underfitting examples

---

### **T4 - Ensemble Methods** 🏗️
**Materials to Review:**
- 📊 `supervised/slides/ensemble.tex`
- 📓 Notebooks: Random Forest, AdaBoost, Gradient Boosting
- 📖 `supervised/tutorials/ensemble-methods.tex`

**Focus Areas:**
- Bagging vs boosting explanations
- Random Forest implementation details
- Feature importance calculations
- Bias-variance trade-offs in ensembles

---

### **T5 - Support Vector Machines (SVM)** ⚡
**Materials to Review:**
- 📊 `supervised/slides/svm-intro.tex`, `svm-kernel.tex`, `svm-soft-margin.tex`
- 📓 Notebooks: SVM implementations, kernel methods
- 📖 `supervised/tutorials/svm.tex`

**Focus Areas:**
- Margin maximization concepts
- Kernel trick explanations
- Dual formulation and KKT conditions
- Soft margin SVM for non-separable data

---

### **T6 - Naive Bayes** 🎯
**Materials to Review:**
- 📊 `supervised/slides/naive-bayes.tex`, `bayesian-nets.tex`
- 📓 Notebooks: Gaussian/Multinomial Naive Bayes
- 📖 `supervised/tutorials/naive-bayes.tex`

**Focus Areas:**
- Conditional independence assumptions
- Different variants (Gaussian, Multinomial, Bernoulli)
- Laplace smoothing
- Text classification applications

---

### **T7 - K-Nearest Neighbors (KNN)** 🎯
**Materials to Review:**
- 📊 `supervised/slides/knn.tex`, `knn-approx.tex`
- 📓 Notebooks: KNN implementations, distance metrics
- 📖 `supervised/tutorials/knn.tex`

**Focus Areas:**
- Distance metrics (Euclidean, Manhattan, etc.)
- Curse of dimensionality
- Approximate nearest neighbor methods
- Choice of k parameter

---

### **T8 - Cross-Validation & Model Selection** 🔄
**Materials to Review:**
- 📊 `supervised/slides/cross-validation.tex`
- 📓 Notebooks: CV implementations, model selection
- 📖 `supervised/tutorials/cross-validation.tex`

**Focus Areas:**
- Different CV strategies (k-fold, stratified, etc.)
- Training/validation/test set splits
- Hyperparameter tuning
- Model evaluation metrics

---

### **T9 - Bias-Variance Trade-off** ⚖️
**Materials to Review:**
- 📊 `supervised/slides/bias-variance.tex`, `bias-variance-2.tex`
- 📓 Notebooks: Bias-variance decomposition examples
- 📖 `supervised/tutorials/bias-variance.tex`

**Focus Areas:**
- Mathematical decomposition of prediction error
- Underfitting vs overfitting examples
- Model complexity effects
- Visualizations of bias-variance trade-off

---

### **T10 - Regularization & Feature Selection** 🎛️
**Materials to Review:**
- 📊 `supervised/slides/ridge-regression.tex`, `lasso-regression.tex`, `feature-selection.tex`
- 📓 Notebooks: Ridge/Lasso implementations, feature selection methods
- 📖 `supervised/tutorials/lasso-regression.tex`, `feature-selection.tex`

**Focus Areas:**
- L1 vs L2 regularization
- Feature selection techniques
- Regularization parameter selection
- Sparsity and feature elimination

---

### **T11 - Advanced Topics & Integration** 🚀
**Materials to Review:**
- 📊 `supervised/slides/movie-recommendation.tex`
- 📓 `supervised/tutorials/matrix-factorization.tex`
- 📊 Any remaining slides or special topics
- 🔍 **Cross-cutting review**: Check consistency across all materials

**Focus Areas:**
- Matrix factorization techniques
- Recommendation systems
- Integration between topics
- Overall course flow and consistency
- Missing connections between concepts

---

## 📝 Review Instructions

### **For Each TA:**

1. **Read the Bug Report Guide**: Thoroughly review `TA_BUG_REPORT_GUIDE.md` first
2. **Test Everything**: 
   - Compile LaTeX slides
   - Run all notebooks
   - Check all figure references
3. **Document Issues**: Use the provided issue template
4. **Prioritize**: Focus on High → Medium → Low priority issues

### **Deliverables (per TA):**
- [ ] **Bug Report**: Detailed list of issues found
- [ ] **Suggestions**: Recommendations for improvements
- [ ] **Examples**: Propose additional examples or exercises
- [ ] **Quiz Questions**: Suggest assessment questions

---

## 🎯 Timeline

| Phase | Duration | Tasks |
|-------|----------|-------|
| **Week 1** | Days 1-3 | Initial review, major issues |
| **Week 2** | Days 4-7 | Detailed analysis, suggestions |
| **Week 3** | Days 8-10 | Final report, cross-checks |

---

## 📊 Progress Tracking

### **Completion Checklist:**
- [ ] T1 - Linear Regression *(TA Name)*
- [ ] T2 - Logistic Regression *(TA Name)*
- [ ] T3 - Decision Trees *(TA Name)*
- [ ] T4 - Ensemble Methods *(TA Name)*
- [ ] T5 - SVM *(TA Name)*
- [ ] T6 - Naive Bayes *(TA Name)*
- [ ] T7 - KNN *(TA Name)*
- [ ] T8 - Cross-Validation *(TA Name)*
- [ ] T9 - Bias-Variance *(TA Name)*
- [ ] T10 - Regularization *(TA Name)*
- [ ] T11 - Advanced Topics *(TA Name)*

---

## 💬 Communication

- **Questions**: Contact course instructor
- **Coordination**: Use shared Slack/Discord channel
- **Updates**: Weekly progress reports
- **Issues**: Log in shared tracking system

---

## 🏆 Evaluation Criteria

TAs will be evaluated on:
- **Thoroughness**: Completeness of review
- **Quality**: Accuracy and usefulness of feedback
- **Timeliness**: Meeting deadlines
- **Collaboration**: Helping improve overall course quality

---

*Thank you for helping make our ML course materials excellent! Your careful review will directly benefit student learning.* 🎓✨