\documentclass[usenames,dvipsnames]{beamer}
\usepackage{../../shared/styles/custom}
\usepackage{../../shared/styles/conventions}

	\title{Conventions, Accuracy Metrics, Classification, Regression}
\date{\today}
\author{Nipun Batra}
\institute{IIT Gandhinagar}
\begin{document}
%\input{../../conventions-sanitized.tex}

  % Define counter for pop quizzes

  \maketitle
  
  % Table of Contents
  \begin{frame}Let us work on the digit recognition problem.

		\begin{figure}[htp]
			\centering
			\begin{notebookbox}{https://nipunbatra.github.io/ml-teaching/notebooks/rule-based-vs-ml.html}
			  \includegraphics[scale=0.35]{../assets/accuracy-convention/figures/mnist.pdf}
			\end{notebookbox}
		  \end{figure}

	\end{frame}

\begin{frame}Maybe 4 can be thought of as: $\bm{|}$ + $\bm{\rule[0.5ex]{1em}{.95pt}}$ + $\bm{|}$ + another vertically down $\bm{|}$
	
	\item \pause The heights of each of the $\bm{|}$ need to be similar within tolerance
	
	\item \pause Each of the $\bm{|}$ can be slightly slanted. Similarly the horizontal line can be slanted.
	\item \pause There can be some cases of 4 where the first $\bm{|}$ is at 45 degrees
	\item \pause There can be some cases of 4 where the width of each stroke is different
	
\end{itemize}

\end{frame}	

\section{Machine Learning Fundamentals}

\begin{frame}Size
	\item \pause Colour
	\item \pause Texture
\end{itemize}
\end{frame}
  
\begin{frame}Answer: Usually no! Sample numbers are typically arbitrary identifiers and not meaningful features. Let us remove it.

\pause Let us modify our data table for now.

\begin{table}[]
	\begin{tabular}{|l|l|l||l|}
		\hline 
		\textbf{Colour} & \textbf{Size} & \textbf{Texture} & \textbf{Condition} \\ \hline 
		Orange & Small & Smooth  & Good      \\
		Red    & Small  & Rough  & Good \\
		Orange & Medium & Smooth & Bad \\
		Yellow & Large  & Smooth & Bad \\ \hline 

	\end{tabular}
\end{table}
\end{frame}

\begin{frame}The training set consists of two parts:
\begin{enumerate}
	\item \pause \color{Lavender}{Features (Input Variables)}
	\item \pause \color{Tan}{Output or Response Variable}
\end{enumerate}
\end{frame}

\begin{frame}We call this matrix as $\cD$, containing:
\begin{enumerate}
	\item Feature matrix ($\mX \in \Real^{n \times d}$) containing data of $n$ samples each of which is $d$ dimensional.
	\item Output vector ($\vy \in \Real^n$) containing output variable for $n$ samples.
\end{enumerate}

\end{frame}

\begin{frame}Example (after encoding): $\vx_1 = \begin{bmatrix}
	1 \\ 
	0 \\
	1 \\
	\end{bmatrix}$ (Orange=1, Small=0, Smooth=1)
	\item \pause Complete dataset: $\cD = \{(\vx_i\tp, y_i)\}_{i=1}^n$
\end{itemize}

\end{frame}

\begin{frame}Learn $f$: 		$\text{Condition} = f(\text{colour, size, texture})$
	\item \pause From Training Dataset
	\item \pause To Predict the condition for the Testing set
\end{enumerate}

\begin{table}[]
	\begin{tabular}{|l|l|l||l|}
		\hline 
		
		\textbf{Colour} & \textbf{Size} & \textbf{Texture} & \textbf{Condition} \\ \hline 
		Orange & Small & Smooth  & Good      \\
		Red    & Small  & Rough  & Good \\
		Orange & Medium & Smooth & Bad \\
		Yellow & Large  & Smooth & Bad \\ \hline
		Red    & Large  & Rough  & ? \\
		Orange &  Large & Rough  & ? \\ \hline          
	\end{tabular}
\end{table}
\end{frame}

\begin{frame}A: Ideally, no!
	\item \pause Ideally - we want to predict ``well'' on all possible inputs. But, can we test that?
	\item \pause No! Since, the test set is only a sample from all possible inputs.
\end{itemize}

\end{frame}

\begin{frame}Both the training set and the test set are samples drawn from the hidden true distribution (also sometimes called population)

\pause More discussion later once we study bias and variance
\end{frame}

\begin{frame}\# People (More people $\implies$ More Energy)
	\item \pause Temperature (Higher Temp. $\implies$ Higher Energy)

\pause \begin{table}[]
	\begin{tabular}{|l|l||l|}
		\hline 
		
		\textbf{\# People} & \textbf{Temp (C)} &  \textbf{Energy (kWh)} \\ \hline 
		
		4000 & 30 & 30 \\
		4200 & 30 & 32 \\
		4200 & 35 & 40 \\ \hline
		3000 & 20& ? \\
		1000 & 45 & ? \\ \hline          
	\end{tabular}
\end{table}	
\end{itemize}

\end{frame}

\section{Classification vs Regression}

\begin{frame}Output variable is discrete
		\item \pause i.e.  $y_i \in \{1, 2, \ldots, k\}$ where $k$ is number of classes 
		\item \pause Examples - Predicting: 
		\begin{itemize}
\item \pause Will I get a loan? (Yes, No)
			\item \pause What is the quality of fruit? (Good, Bad)
		\end{itemize}
	\end{itemize}
	\item \pause Regression
	\begin{itemize}
\item \pause Output variable is continuous
		\item \pause i.e.  $y_i \in \Real$ 
		\pause
\item \pause Examples - Predicting: 
		\begin{itemize}
			\item \pause How much energy will campus consume? 
			\item \pause How much rainfall will fall?
		\end{itemize}
	\end{itemize}
\end{itemize}

\end{frame}

%\captionsetup[subtable]{labelformat=empty}
%
%\begin{frame}\begin{align*}
\text{Accuracy} &= \frac{|\{i : y_i = \hat{y}_i\}|}{n} \\ 
&= \frac{3}{5} = 0.6
\end{align*}

\end{frame}

\begin{frame}\textbf{Set cardinality notation:} $|\{i : y_i = \hat{y}_i\}|$ 
	\begin{itemize}
\item Reads as: ``Number of indices $i$ such that $y_i = \hat{y}_i$''
		\item Counts how many samples satisfy the condition
	\end{itemize}
	
	\item \pause \textbf{Alternative: Indicator function notation}
	\begin{align*}
	\text{Accuracy} &= \frac{\sum_{i=1}^n \mathbf{1}[y_i = \hat{y}_i]}{n}
	\end{align*}
	where $\mathbf{1}[\text{condition}] = \begin{cases} 1 & \text{if condition is true} \\ 0 & \text{if condition is false} \end{cases}$
	
	\item \pause Both notations are mathematically equivalent and commonly used in ML literature
\end{itemize}
\end{frame}

\begin{frame}Cases for this:
\begin{itemize}
\item Cancer Screening
\item Planet Detection
\end{itemize}

\end{frame}

\begin{frame}\text{Precision} &= \frac{|\{i : y_i = \hat{y}_i = \text{Good}\}|}{|\{i : \hat{y}_i = \text{Good}\}|} = \frac{2}{4} = 0.5
\end{align*}

``the fraction of relevant instances among the retrieved instances'', i.e. ``out of the number of times we predict \text{Good}, how many times is the condition actually \text{Good}''

\end{frame}

\begin{frame}\begin{align*}
\text{Accuracy} = \frac{98}{100} = 0.98 \qquad \qquad \qquad
\text{Recall} &= \frac{0}{1} = 0 \\
\text{Precision} &= \frac{0}{1} = 0
\end{align*}

\end{frame}

\begin{frame}\vspace{60pt}
\begin{tabular}{@{}cc cc@{}}
	\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Ground Truth} \\ 
	\cmidrule(lr){3-4}
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c}{Yes} & 
	\multicolumn{1}{c}{No} \\ 
	\cline{2-4}
	\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Predicted}}
	& Yes  & True Positive & False Positive   \\[1.5ex]
	& No  & False Negative   & True Negative \\ 
	\cline{2-4}
\end{tabular}
\end{center}
\end{frame}

\begin{frame}$$
%\bordermatrix{&\text{G.T. Positive}&\text{G.T. Negative}\cr
%               \text{Pred Positive}&0&1\cr
%               \text{Pred Negative}&1&98}
%$$
%\pause $$
%\bordermatrix{&\text{G.T. Positive}&\text{G.T. Negative}\cr
%               \text{Pred Positive}&\text{True Positive}&\text{False Positive}\cr
%               \text{Pred Negative}&\text{True Negative}&\text{False Negative}}
%$$
%
%
%\pause \begin{align*}
%\text{Recall} = \frac{\text{T.P}}{\text{T.P + F.P}} \qquad \qquad 
%\text{Precision} = \frac{\text{T.P}}{\text{T.P + F.N}}
%\end{align*}
%\end{frame}

\begin{frame}Is there any downside with using mean error?\\
\pause Errors can get cancelled out

\end{frame}

\section{Data Visualization and Baselines}

\begin{frame}\textbf{Answer:} c) Precision, recall, and F1-score give a more complete picture!
\end{tcolorbox}
\end{frame}

\begin{frame}{Key Takeaways}
\begin{itemize}
\item \textbf{ML vs Traditional Programming:} ML learns rules from data, traditional programming uses predefined rules
	\pause
\item \textbf{Features matter:} Choose meaningful features, avoid arbitrary identifiers
	\pause
\item \textbf{Classification vs Regression:} Discrete outputs vs continuous outputs
	\pause
\item \textbf{Accuracy isn't everything:} For imbalanced data, use precision, recall, F1-score
	\pause
\item \textbf{Visualization is crucial:} Always plot your data (Anscombe's Quartet lesson)
	\pause
\item \textbf{Use baselines:} Simple baseline models help validate your approach
\end{itemize}
\end{frame}

\begin{frame}{Summary: Evaluation Metrics}
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Task} & \textbf{Common Metrics} & \textbf{When to Use} \\
\hline
\textbf{Classification} & Accuracy, Precision, Recall, F1 & Balanced/Imbalanced data \\
 & Confusion Matrix & Multi-class problems \\
\hline
\textbf{Regression} & MSE, RMSE, MAE & Continuous predictions \\
 & Mean Error & Check for bias \\
\hline
\end{tabular}
\end{center}

\vspace{1cm}
\textbf{Remember:} Choose metrics based on your problem's characteristics and business requirements!
\end{frame}

\end{document}
