\documentclass[dvipsnames]{beamer}
\usepackage{../../shared/styles/custom}
\usepackage{../../shared/styles/conventions}

	\title{Conventions, Accuracy Metrics, Classification, Regression}
\date{\today}
\author{Nipun Batra}
\institute{IIT Gandhinagar}
\begin{document}
%\input{../../conventions-sanitized.tex}

  % Define counter for pop quizzes

  \maketitle
  
  \begin{frame}{Outline}
    \tableofcontents
  \end{frame}

  \section{Introduction to Machine Learning}
  
  \begin{frame}{Digit Recognition Problem}
  Let us work on the digit recognition problem.

		\begin{figure}[htp]
			\centering
			\begin{notebookbox}{https://nipunbatra.github.io/ml-teaching/notebooks/rule-based-vs-ml.html}
			  \includegraphics[scale=0.35]{../assets/accuracy-convention/figures/mnist.pdf}
			\end{notebookbox}
		  \end{figure}

	\end{frame}

\begin{frame}{Rule-based Approach for Digit Recognition}
Maybe 4 can be thought of as: $\bm{|}$ + $\bm{\rule[0.5ex]{1em}{.95pt}}$ + $\bm{|}$ + another vertical $\bm{|}$

\begin{itemize}
	\item \pause The heights of each of the $\bm{|}$ need to be similar within tolerance
	
	\item \pause Each of the $\bm{|}$ can be slightly slanted. Similarly the horizontal line can be slanted.
	\item \pause There can be some cases of 4 where the first $\bm{|}$ is at 45 degrees
	\item \pause There can be some cases of 4 where the width of each stroke is different
	
\end{itemize}

\end{frame}	

\section{Machine Learning Fundamentals}

\begin{frame}{Pop Quiz: Rule-Based vs ML}
\begin{popquizbox}{1}
Why is it difficult to write rules for digit recognition?
\begin{enumerate}
\item[a)] Digits are always the same
\item[b)] Variations in handwriting, rotation, thickness make rules complex
\item[c)] Rules are faster than ML
\end{enumerate}

\vspace{0.5em}
\textbf{Answer:} b) Handwriting variations make rule-based approaches extremely complex!
\end{popquizbox}
\end{frame}

\begin{frame}{Apple Quality Features}
\begin{itemize}
	\item Size
	\item \pause Colour
	\item \pause Texture
\end{itemize}
\end{frame}
  
\begin{frame}{Should We Include Sample Numbers?}
Answer: Usually no! Sample numbers are typically arbitrary identifiers and not meaningful features. Let us remove it.

\pause Let us modify our data table for now.

\begin{table}[]
	\begin{tabular}{|l|l|l||l|}
		\hline 
		\textbf{Colour} & \textbf{Size} & \textbf{Texture} & \textbf{Condition} \\ \hline 
		Orange & Small & Smooth  & Good      \\
		Red    & Small  & Rough  & Good \\
		Orange & Medium & Smooth & Bad \\
		Yellow & Large  & Smooth & Bad \\ \hline 

	\end{tabular}
\end{table}
\end{frame}

\begin{frame}{Training Set Components}
The training set consists of two parts:
\begin{enumerate}
	\item \pause \color{Lavender}{Features (Input Variables)}
	\item \pause \color{Tan}{Output or Response Variable}
\end{enumerate}
\end{frame}

\begin{frame}{Dataset Notation}
We call this matrix as $\cD$, containing:
\begin{enumerate}
	\item Feature matrix ($\mX \in \Real^{n \times d}$) containing data of $n$ samples each of which is $d$ dimensional.
	\item Output vector ($\vy \in \Real^n$) containing output variable for $n$ samples.
\end{enumerate}

\end{frame}

\begin{frame}{Dataset Example}
Example (after encoding): $\vx_1 = \begin{bmatrix}
	1 \\ 
	0 \\
	1 \\
	\end{bmatrix}$ (Orange=1, Small=0, Smooth=1)

\begin{itemize}
	\item \pause Complete dataset: $\cD = \{(\vx_i\tp, y_i)\}_{i=1}^n$
\end{itemize}

\end{frame}

\begin{frame}{Machine Learning Goal}
Learn $f$: 		$\text{Condition} = f(\text{colour, size, texture})$

\begin{enumerate}
	\item \pause From Training Dataset
	\item \pause To Predict the condition for the Testing set
\end{enumerate}

\begin{table}[]
	\begin{tabular}{|l|l|l||l|}
		\hline 
		
		\textbf{Colour} & \textbf{Size} & \textbf{Texture} & \textbf{Condition} \\ \hline 
		Orange & Small & Smooth  & Good      \\
		Red    & Small  & Rough  & Good \\
		Orange & Medium & Smooth & Bad \\
		Yellow & Large  & Smooth & Bad \\ \hline
		Red    & Large  & Rough  & ? \\
		Orange &  Large & Rough  & ? \\ \hline          
	\end{tabular}
\end{table}
\end{frame}

\begin{frame}{Can We Judge Performance Only on Test Set?}
A: Ideally, no!

\begin{itemize}
	\item \pause Ideally - we want to predict ``well'' on all possible inputs. But, can we test that?
	\item \pause No! Since, the test set is only a sample from all possible inputs.
\end{itemize}

\end{frame}

\begin{frame}{Training vs Test Sets}
Both the training set and the test set are samples drawn from the hidden true distribution (also sometimes called population)

\pause More discussion later once we study bias and variance
\end{frame}

\begin{frame}{Energy Consumption Example}
\begin{itemize}
	\item \# People (More people $\implies$ More Energy)
	\item \pause Temperature (Higher Temp. $\implies$ Higher Energy)
\end{itemize}

\pause \begin{table}[]
	\begin{tabular}{|l|l||l|}
		\hline 
		
		\textbf{\# People} & \textbf{Temp (C)} &  \textbf{Energy (kWh)} \\ \hline 
		
		4000 & 30 & 30 \\
		4200 & 30 & 32 \\
		4200 & 35 & 40 \\ \hline
		3000 & 20& ? \\
		1000 & 45 & ? \\ \hline          
	\end{tabular}
\end{table}
\end{frame}

\begin{frame}{Pop Quiz: Training Data}
\begin{popquizbox}{2}
What makes a good feature for machine learning?
\begin{enumerate}
\item[a)] Sample ID numbers
\item[b)] Meaningful characteristics that relate to the output
\item[c)] Random numbers
\end{enumerate}

\vspace{0.5em}
\textbf{Answer:} b) Features should be meaningful and related to what you're predicting!
\end{popquizbox}
\end{frame}

\section{Classification vs Regression}

\begin{frame}{Classification vs Regression}
\begin{itemize}
	\item Classification
	\begin{itemize}
		\item \pause Output variable is discrete
		\item \pause i.e.  $y_i \in \{1, 2, \ldots, k\}$ where $k$ is number of classes 
		\item \pause Examples - Predicting: 
		\begin{itemize}
			\item \pause Will I get a loan? (Yes, No)
			\item \pause What is the quality of fruit? (Good, Bad)
		\end{itemize}
	\end{itemize}
	\item \pause Regression
	\begin{itemize}
		\item \pause Output variable is continuous
		\item \pause i.e.  $y_i \in \Real$ 
		\item \pause Examples - Predicting: 
		\begin{itemize}
			\item \pause How much energy will campus consume? 
			\item \pause How much rainfall will fall?
		\end{itemize}
	\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Pop Quiz: Problem Types}
\begin{popquizbox}{3}
Predicting house prices is an example of:
\begin{enumerate}
\item[a)] Classification (discrete output)
\item[b)] Regression (continuous output)
\item[c)] Neither
\end{enumerate}

\vspace{0.5em}
\textbf{Answer:} b) Regression - house prices are continuous values!
\end{popquizbox}
\end{frame}

\section{Evaluation Metrics}

\begin{frame}{Accuracy Calculation}
\[
\text{Accuracy} = \frac{|\{i : y_i = \hat{y}_i\}|}{n} = \frac{3}{5} = 0.6
\]
\end{frame}

\begin{frame}{Accuracy Notation}
\begin{itemize}
	\item \textbf{Set cardinality notation:} $|\{i : y_i = \hat{y}_i\}|$ 
	\begin{itemize}
		\item Reads as: ``Number of indices $i$ such that $y_i = \hat{y}_i$''
		\item Counts how many samples satisfy the condition
	\end{itemize}
	
	\item \pause \textbf{Alternative: Indicator function notation}
	\begin{align*}
	\text{Accuracy} &= \frac{\sum_{i=1}^n \mathbf{1}[y_i = \hat{y}_i]}{n}
	\end{align*}
	where $\mathbf{1}[\text{condition}] = \begin{cases} 1 & \text{if condition is true} \\ 0 & \text{if condition is false} \end{cases}$
	
	\item \pause Both notations are mathematically equivalent and commonly used in ML literature
\end{itemize}
\end{frame}

\begin{frame}{When Precision/Recall Matter}
Cases for this:
\begin{itemize}
\item Cancer Screening
\item Planet Detection
\end{itemize}

\end{frame}

\begin{frame}{Precision Metric}
\begin{align*}
\text{Precision} &= \frac{|\{i : y_i = \hat{y}_i = \text{Good}\}|}{|\{i : \hat{y}_i = \text{Good}\}|} = \frac{2}{4} = 0.5
\end{align*}

\textbf{Definition:} ``The fraction of relevant instances among the retrieved instances''

\textbf{In simple terms:} Out of all times we predict ``Good'', how many times is it actually ``Good''?

\end{frame}

\begin{frame}{Accuracy vs Precision/Recall}
\begin{align*}
\text{Accuracy} &= \frac{98}{100} = 0.98 \\
\text{Recall} &= \frac{0}{1} = 0 \\
\text{Precision} &= \frac{0}{1} = 0
\end{align*}

\end{frame}

\begin{frame}{Confusion Matrix}
\vspace{5pt}
\begin{center}
\begin{tabular}{@{}cc cc@{}}
	\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{\textbf{Ground Truth}} \\ 
	\cmidrule(lr){3-4}
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c}{Positive} & 
	\multicolumn{1}{c}{Negative} \\ 
	\cline{2-4}
	\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{\textbf{Predicted}}}
	& Positive  & \cellcolor{blue!60}\textbf{True Positive (TP)} & \cellcolor{orange!70}\textbf{False Positive (FP)}   \\[1.2ex]
	& Negative  & \cellcolor{red!70}\textbf{False Negative (FN)}   & \cellcolor{gray!30}\textbf{True Negative (TN)} \\ 
	\cline{2-4}
\end{tabular}
\end{center}
\vspace{8pt}
\pause
\begin{alertblock}{Key Insight}
Each cell represents a different type of prediction outcome:
\vspace{-0.5em}
\begin{itemize}
\item \colorbox{blue!60}{TP}: Correctly predicted positive
\item \colorbox{orange!70}{FP}: Incorrectly predicted positive  
\item \colorbox{red!70}{FN}: Missed a positive (dangerous!)
\item \colorbox{gray!30}{TN}: Correctly predicted negative
\end{itemize}
\end{alertblock}
\end{frame}

\begin{frame}{Precision: "How accurate are my positive predictions?"}
\vspace{2pt}
\begin{center}
\begin{tabular}{@{}cc cc@{}}
	\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{\textbf{Ground Truth}} \\ 
	\cmidrule(lr){3-4}
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c}{Positive} & 
	\multicolumn{1}{c}{Negative} \\ 
	\cline{2-4}
	\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{\textbf{Predicted}}}
	& \colorbox{yellow!40}{Positive}  & \cellcolor{blue!60}\textbf{TP} & \cellcolor{orange!70}\textbf{FP}   \\[1.2ex]
	& Negative  & \cellcolor{gray!30}FN   & \cellcolor{gray!30}TN \\ 
	\cline{2-4}
\end{tabular}
\end{center}
\vspace{6pt}
$$\text{Precision} = \frac{\colorbox{blue!60}{\text{TP}}}{\colorbox{yellow!40}{\colorbox{blue!60}{\text{TP}} + \colorbox{orange!70}{\text{FP}}}} = \frac{\text{Correct Positives}}{\text{All Predicted Positives}}$$
\pause
\vspace{-0.3em}
\begin{alertblock}{Focus: Look at the PREDICTED POSITIVE ROW}
\textbf{Question:} When I predict "positive", how often am I right?\\
\textbf{Answer:} Out of all my positive predictions (TP + FP), TP are correct.
\end{alertblock}
\end{frame}

\begin{frame}{Recall: "How many actual positives did I find?"}
\vspace{2pt}
\begin{center}
\begin{tabular}{@{}cc cc@{}}
	\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{\textbf{Ground Truth}} \\ 
	\cmidrule(lr){3-4}
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c}{\colorbox{yellow!40}{Positive}} & 
	\multicolumn{1}{c}{Negative} \\ 
	\cline{2-4}
	\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{\textbf{Predicted}}}
	& Positive  & \cellcolor{blue!60}\textbf{TP} & \cellcolor{gray!30}FP   \\[1.2ex]
	& Negative  & \cellcolor{red!70}\textbf{FN}   & \cellcolor{gray!30}TN \\ 
	\cline{2-4}
\end{tabular}
\end{center}
\vspace{6pt}
$$\text{Recall} = \frac{\colorbox{blue!60}{\text{TP}}}{\colorbox{yellow!40}{\colorbox{blue!60}{\text{TP}} + \colorbox{red!70}{\text{FN}}}} = \frac{\text{Correct Positives}}{\text{All Actual Positives}}$$
\pause
\vspace{-0.3em}
\begin{alertblock}{Focus: Look at the ACTUAL POSITIVE COLUMN}
\textbf{Question:} Of all things that ARE positive, how many did I catch?\\
\textbf{Answer:} Out of all actual positives (TP + FN), I found TP of them.
\end{alertblock}
\end{frame}

\begin{frame}{Example: Medical Diagnosis}
Let's say we're testing for a disease:
\vspace{5pt}
\begin{center}
\begin{tabular}{@{}cc cc@{}}
	\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{\textbf{Actually Has Disease}} \\ 
	\cmidrule(lr){3-4}
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c}{Yes} & 
	\multicolumn{1}{c}{No} \\ 
	\cline{2-4}
	\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{\textbf{Test Says}}}
	& Positive  & \cellcolor{blue!60}\textbf{90} & \cellcolor{orange!70}\textbf{10}   \\[1.2ex]
	& Negative  & \cellcolor{red!70}\textbf{5}   & \cellcolor{gray!30}\textbf{895} \\ 
	\cline{2-4}
\end{tabular}
\end{center}
\vspace{5pt}
\pause
\begin{align*}
\text{Precision} &= \frac{\colorbox{blue!60}{90}}{\colorbox{blue!60}{90} + \colorbox{orange!70}{10}} = \frac{90}{100} = 0.90 \text{ (90\%)} \\
\pause
\text{Recall} &= \frac{\colorbox{blue!60}{90}}{\colorbox{blue!60}{90} + \colorbox{red!70}{5}} = \frac{90}{95} = 0.95 \text{ (95\%)} \\
\pause
\text{Accuracy} &= \frac{\colorbox{blue!60}{90} + \colorbox{gray!30}{895}}{1000} = 0.985 \text{ (98.5\%)}
\end{align*}
\end{frame}


\begin{frame}{Mean Error Issues}
Is there any downside with using mean error?
\pause Errors can get cancelled out

\end{frame}

\begin{frame}{Pop Quiz: Metrics Choice}
\begin{popquizbox}{4}
For cancer detection (1 positive case in 1000), which metric is most important?
\begin{enumerate}
\item[a)] Accuracy only
\item[b)] Recall (finding all cancer cases)
\item[c)] Speed of prediction
\end{enumerate}

\vspace{0.5em}
\textbf{Answer:} b) Recall - we cannot afford to miss cancer cases!
\end{popquizbox}
\end{frame}

\section{Advanced Topics}

\begin{frame}{Pop Quiz}
\begin{popquizbox}{1}
Which metrics should you use for imbalanced datasets?
\begin{enumerate}
\item Accuracy only  
\item Mean squared error
\item Precision, recall, and F1-score
\end{enumerate}

\vspace{0.5em}
\textbf{Answer:} c) Precision, recall, and F1-score give a more complete picture!
\end{popquizbox}
\end{frame}

\begin{frame}{Key Takeaways}
\begin{itemize}
\item \textbf{ML vs Traditional Programming:} \\
      ML learns rules from data, traditional programming uses predefined rules
	\pause
\item \textbf{Features matter:} \\
      Choose meaningful features, avoid arbitrary identifiers
	\pause
\item \textbf{Classification vs Regression:} \\
      Discrete outputs vs continuous outputs
	\pause
\item \textbf{Accuracy isn't everything:} \\
      For imbalanced data, use precision, recall, F1-score
	\pause
\item \textbf{Visualization is crucial:} \\
      Always plot your data first
	\pause
\item \textbf{Use baselines:} \\
      Simple baseline models help validate your approach
\end{itemize}
\end{frame}

\begin{frame}{Summary: Evaluation Metrics}
\begin{center}
\resizebox{0.95\textwidth}{!}{%
\begin{tabular}{|l|l|l|}
\hline
\textbf{Task} & \textbf{Common Metrics} & \textbf{When to Use} \\
\hline
\textbf{Classification} & Accuracy, Precision, Recall, F1 & Balanced/Imbalanced data \\
 & Confusion Matrix & Multi-class problems \\
\hline
\textbf{Regression} & MSE, RMSE, MAE & Continuous predictions \\
 & Mean Error & Check for bias \\
\hline
\end{tabular}
}
\end{center}

\vspace{1cm}
\vspace{0.5em}
\begin{alertblock}{Remember}
Choose metrics based on your problem's characteristics and business requirements!
\end{alertblock}
\end{frame}

\end{document}
