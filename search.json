[
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Lecture Slides",
    "section": "",
    "text": "Fundamental concepts and prerequisites for machine learning.\n\nIntroduction and Logistics\nConvention, Metrics, Classification, Regression\nData Shuffling\nMiscellaneous Topics\n\n\n\n\nCore mathematical concepts underlying machine learning algorithms.\n\nMathematical Foundations\nContour Plots & Visualization\nMultivariate Normal Distribution\nMultivariate Normal II\nKKT Conditions\nFinding Widths\nTime Complexity\n\n\n\n\nTechniques for finding optimal solutions in machine learning.\n\nGradient Descent\nCoordinate Descent\nSubgradient Methods\nConvexity\nStochastic Gradient Descent\n\n\n\n\nAlgorithms that learn from labeled data.\n\nDecision Trees\nBias-Variance Tradeoff\nBias-Variance II\nCross-Validation\nEnsemble Methods\nLinear Regression\nLogistic Regression\nK-Nearest Neighbors\nNaive Bayes\nBayesian Networks\nRidge Regression\nLasso Regression\nFeature Selection\nSVM Introduction\nSVM Soft Margin\nSVM Kernel Methods\nMore SVM Topics\n\n\n\n\nModern neural network architectures and deep learning techniques.\n\nMulti-Layer Perceptrons\nConvolutional Neural Networks\n1D CNNs\nAutomatic Differentiation\n\n\n\n\nSpecialized techniques and cutting-edge approaches.\n\nTime Series Forecasting\nReinforcement Learning\n\n\n\n\nAlgorithms that find patterns in unlabeled data.\n\nClustering & Dimensionality Reduction"
  },
  {
    "objectID": "slides.html#course-materials-by-category",
    "href": "slides.html#course-materials-by-category",
    "title": "Lecture Slides",
    "section": "",
    "text": "Fundamental concepts and prerequisites for machine learning.\n\nIntroduction and Logistics\nConvention, Metrics, Classification, Regression\nData Shuffling\nMiscellaneous Topics\n\n\n\n\nCore mathematical concepts underlying machine learning algorithms.\n\nMathematical Foundations\nContour Plots & Visualization\nMultivariate Normal Distribution\nMultivariate Normal II\nKKT Conditions\nFinding Widths\nTime Complexity\n\n\n\n\nTechniques for finding optimal solutions in machine learning.\n\nGradient Descent\nCoordinate Descent\nSubgradient Methods\nConvexity\nStochastic Gradient Descent\n\n\n\n\nAlgorithms that learn from labeled data.\n\nDecision Trees\nBias-Variance Tradeoff\nBias-Variance II\nCross-Validation\nEnsemble Methods\nLinear Regression\nLogistic Regression\nK-Nearest Neighbors\nNaive Bayes\nBayesian Networks\nRidge Regression\nLasso Regression\nFeature Selection\nSVM Introduction\nSVM Soft Margin\nSVM Kernel Methods\nMore SVM Topics\n\n\n\n\nModern neural network architectures and deep learning techniques.\n\nMulti-Layer Perceptrons\nConvolutional Neural Networks\n1D CNNs\nAutomatic Differentiation\n\n\n\n\nSpecialized techniques and cutting-edge approaches.\n\nTime Series Forecasting\nReinforcement Learning\n\n\n\n\nAlgorithms that find patterns in unlabeled data.\n\nClustering & Dimensionality Reduction"
  },
  {
    "objectID": "slides.html#how-to-use-these-materials",
    "href": "slides.html#how-to-use-these-materials",
    "title": "Lecture Slides",
    "section": "How to Use These Materials",
    "text": "How to Use These Materials\n\nFor Students: Navigate through topics sequentially, starting with Basics & Foundations\nFor Instructors: Each category is self-contained and can be taught independently\nPDF Quality: All slides are optimized for both viewing and printing"
  },
  {
    "objectID": "slides.html#quick-links",
    "href": "slides.html#quick-links",
    "title": "Lecture Slides",
    "section": "Quick Links",
    "text": "Quick Links\n\nInteractive Notebooks - Hands-on coding examples\nCourse Homepage - Return to main page\nInstructor - Nipun Batra’s homepage"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Course",
    "section": "",
    "text": "Welcome to a complete collection of machine learning course materials developed at IIT Gandhinagar. This resource combines theoretical foundations with practical implementations, designed for both students and instructors.\n\n\n\n\nOver 100 Jupyter notebooks with hands-on coding examples, from basics to advanced topics. All notebooks are runnable in Google Colab.\n\n\n\nComprehensive slide decks covering all major machine learning topics, organized by category for easy navigation.\n\n\n\nReal-world examples using datasets like MNIST, Iris, and custom problems across computer vision, NLP, and more.\n\n\n\n\nThe materials are organized into six main categories:\n\nBasics & Foundations - Getting started with ML concepts\nMathematical Foundations - Linear algebra, optimization, probability\nSupervised Learning - Regression, classification, model evaluation\nNeural Networks - Deep learning fundamentals and architectures\nAdvanced Topics - Time series, reinforcement learning, modern techniques\nUnsupervised Learning - Clustering, dimensionality reduction\n\n\n\n\n\nNew to ML? Start with Basics & Foundations\nHands-on Learning Browse the interactive notebooks\nTheory First? Explore the lecture slides\nQuick Practice Try the Anscombe’s Quartet notebook\n\n\n\n\nThese materials represent several years of machine learning education at IIT Gandhinagar, developed by Prof. Nipun Batra and dedicated teaching assistants. The content emphasizes both theoretical understanding and practical implementation skills.\n\nFor questions or feedback, visit Prof. Nipun Batra’s homepage"
  },
  {
    "objectID": "index.html#what-youll-find-here",
    "href": "index.html#what-youll-find-here",
    "title": "Machine Learning Course",
    "section": "",
    "text": "Over 100 Jupyter notebooks with hands-on coding examples, from basics to advanced topics. All notebooks are runnable in Google Colab.\n\n\n\nComprehensive slide decks covering all major machine learning topics, organized by category for easy navigation.\n\n\n\nReal-world examples using datasets like MNIST, Iris, and custom problems across computer vision, NLP, and more."
  },
  {
    "objectID": "index.html#course-structure",
    "href": "index.html#course-structure",
    "title": "Machine Learning Course",
    "section": "",
    "text": "The materials are organized into six main categories:\n\nBasics & Foundations - Getting started with ML concepts\nMathematical Foundations - Linear algebra, optimization, probability\nSupervised Learning - Regression, classification, model evaluation\nNeural Networks - Deep learning fundamentals and architectures\nAdvanced Topics - Time series, reinforcement learning, modern techniques\nUnsupervised Learning - Clustering, dimensionality reduction"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Machine Learning Course",
    "section": "",
    "text": "New to ML? Start with Basics & Foundations\nHands-on Learning Browse the interactive notebooks\nTheory First? Explore the lecture slides\nQuick Practice Try the Anscombe’s Quartet notebook"
  },
  {
    "objectID": "index.html#about-the-course",
    "href": "index.html#about-the-course",
    "title": "Machine Learning Course",
    "section": "",
    "text": "These materials represent several years of machine learning education at IIT Gandhinagar, developed by Prof. Nipun Batra and dedicated teaching assistants. The content emphasizes both theoretical understanding and practical implementation skills.\n\nFor questions or feedback, visit Prof. Nipun Batra’s homepage"
  },
  {
    "objectID": "notebooks.html",
    "href": "notebooks.html",
    "title": "Interactive Notebooks",
    "section": "",
    "text": "Interactive notebooks provide practical coding examples and visualizations to complement the lecture slides. All notebooks are runnable in Google Colab or local Jupyter environments.\n\n\n\nAnscombe’s Quartet - Why visualization matters\nVisualization Techniques - Comprehensive plotting guide\nNumPy & Pandas Basics - Essential data manipulation\nBinomial Distribution - Probability foundations\nTips Dataset Analysis - Real-world data exploration\nRule-Based vs ML - When to use ML\n\n\n\n\n\nBasis Functions - Linear algebra foundations\nBasis Functions II - Advanced basis concepts\nContour Plots - Visualizing functions\nMeshgrid & Contours - Grid visualization\nTaylor Series - Mathematical approximations\nPolynomial Features - Feature engineering\nCurse of Dimensionality - High-dimensional problems\n\n\n\n\n\nGradient Descent - Core optimization\nGradient Descent 2D - Visual optimization\nCost vs Iterations - Convergence analysis\nAutomatic Differentiation - Modern backpropagation\n\n\n\n\n\n\n\nLinear Regression - Basic regression\nLinear Regression Tutorial - Step-by-step guide\nGeometric Linear Regression - Visual interpretation\nRidge Regression - Regularized regression\nLasso Regression - Sparse solutions\n\n\n\n\n\nLogistic Regression - PyTorch implementation\nLogistic Regression Cost - Loss function analysis\nLogistic: Apples vs Oranges - Binary classification\nLogistic: Circular Data - Non-linear boundaries\nLogistic: Iris Dataset - Multi-class classification\nLogits Usage - Understanding logits\n\n\n\n\n\nDecision Trees: Discrete → Discrete\nDecision Trees: Real → Discrete\nDecision Trees: Real → Real\nDecision Tree Classes - Classification trees\nWeighted Decision Trees - Sample weighting\nEnsemble Feature Importance\nBoosting Explanation - AdaBoost mechanics\nEnsemble Representations\n\n\n\n\n\nKNN Variants - Different distance metrics\nMovie Recommendation - Collaborative filtering\n\n\n\n\n\nSVM Basics - Introduction to SVMs\nSVM with CVXOPT - Optimization implementation\nSVM Kernel Understanding - Kernel trick\nSVM Kernels - Different kernel functions\nSVM Primal-Dual - Mathematical foundations\nSVM Soft Margin - Handling noise\n\n\n\n\n\n\nBias-Variance Analysis - Fundamental tradeoff\nBias-Variance Charts - Visual analysis\nCross-Validation Diagrams - Validation strategies\nPR Curves - Precision-Recall analysis\nDummy Baselines - Baseline comparisons\nDummy Variables - Encoding issues\nHyperparameter Optimization\nHyperparameter Experiments\nConfusion Matrix: MNIST - Multi-class evaluation\n\n\n\n\n\nPerceptron Learning - Basic neural unit\nConvolutional Operations - CNN fundamentals\nConvolution with Stride - Parameter effects\nCNNs - Complete CNN implementation\n1D CNNs - Sequence processing\nCNN Edge Detection - Feature visualization\nLeNet Architecture - Classic CNN\nVGG on MNIST - Modern CNN\nMNIST Digits - Digit classification\nImage Generation - Generative models\nObject Detection - Computer vision\nSIREN Networks - Implicit neural representations\nNN Vectorization - Efficient implementation\n\n\n\n\n\nPrincipal Component Analysis - Dimensionality reduction\nTensor Factorization - Matrix decomposition\n\n\n\n\n\nAutoregressive Models - Time series prediction\nQ-Learning - Reinforcement learning basics\nDeep Q-Learning - Neural RL\nRL Gym Environments - Practice environments\nFeature Selection - Forward/backward selection\nSklearn on GPU - Performance optimization\nZero/Few Shot Learning - Modern ML paradigms\n\n\n\n\n\nNames Analysis - Text processing\nAudio Transcription - Speech processing"
  },
  {
    "objectID": "notebooks.html#hands-on-learning-with-jupyter-notebooks",
    "href": "notebooks.html#hands-on-learning-with-jupyter-notebooks",
    "title": "Interactive Notebooks",
    "section": "",
    "text": "Interactive notebooks provide practical coding examples and visualizations to complement the lecture slides. All notebooks are runnable in Google Colab or local Jupyter environments.\n\n\n\nAnscombe’s Quartet - Why visualization matters\nVisualization Techniques - Comprehensive plotting guide\nNumPy & Pandas Basics - Essential data manipulation\nBinomial Distribution - Probability foundations\nTips Dataset Analysis - Real-world data exploration\nRule-Based vs ML - When to use ML\n\n\n\n\n\nBasis Functions - Linear algebra foundations\nBasis Functions II - Advanced basis concepts\nContour Plots - Visualizing functions\nMeshgrid & Contours - Grid visualization\nTaylor Series - Mathematical approximations\nPolynomial Features - Feature engineering\nCurse of Dimensionality - High-dimensional problems\n\n\n\n\n\nGradient Descent - Core optimization\nGradient Descent 2D - Visual optimization\nCost vs Iterations - Convergence analysis\nAutomatic Differentiation - Modern backpropagation\n\n\n\n\n\n\n\nLinear Regression - Basic regression\nLinear Regression Tutorial - Step-by-step guide\nGeometric Linear Regression - Visual interpretation\nRidge Regression - Regularized regression\nLasso Regression - Sparse solutions\n\n\n\n\n\nLogistic Regression - PyTorch implementation\nLogistic Regression Cost - Loss function analysis\nLogistic: Apples vs Oranges - Binary classification\nLogistic: Circular Data - Non-linear boundaries\nLogistic: Iris Dataset - Multi-class classification\nLogits Usage - Understanding logits\n\n\n\n\n\nDecision Trees: Discrete → Discrete\nDecision Trees: Real → Discrete\nDecision Trees: Real → Real\nDecision Tree Classes - Classification trees\nWeighted Decision Trees - Sample weighting\nEnsemble Feature Importance\nBoosting Explanation - AdaBoost mechanics\nEnsemble Representations\n\n\n\n\n\nKNN Variants - Different distance metrics\nMovie Recommendation - Collaborative filtering\n\n\n\n\n\nSVM Basics - Introduction to SVMs\nSVM with CVXOPT - Optimization implementation\nSVM Kernel Understanding - Kernel trick\nSVM Kernels - Different kernel functions\nSVM Primal-Dual - Mathematical foundations\nSVM Soft Margin - Handling noise\n\n\n\n\n\n\nBias-Variance Analysis - Fundamental tradeoff\nBias-Variance Charts - Visual analysis\nCross-Validation Diagrams - Validation strategies\nPR Curves - Precision-Recall analysis\nDummy Baselines - Baseline comparisons\nDummy Variables - Encoding issues\nHyperparameter Optimization\nHyperparameter Experiments\nConfusion Matrix: MNIST - Multi-class evaluation\n\n\n\n\n\nPerceptron Learning - Basic neural unit\nConvolutional Operations - CNN fundamentals\nConvolution with Stride - Parameter effects\nCNNs - Complete CNN implementation\n1D CNNs - Sequence processing\nCNN Edge Detection - Feature visualization\nLeNet Architecture - Classic CNN\nVGG on MNIST - Modern CNN\nMNIST Digits - Digit classification\nImage Generation - Generative models\nObject Detection - Computer vision\nSIREN Networks - Implicit neural representations\nNN Vectorization - Efficient implementation\n\n\n\n\n\nPrincipal Component Analysis - Dimensionality reduction\nTensor Factorization - Matrix decomposition\n\n\n\n\n\nAutoregressive Models - Time series prediction\nQ-Learning - Reinforcement learning basics\nDeep Q-Learning - Neural RL\nRL Gym Environments - Practice environments\nFeature Selection - Forward/backward selection\nSklearn on GPU - Performance optimization\nZero/Few Shot Learning - Modern ML paradigms\n\n\n\n\n\nNames Analysis - Text processing\nAudio Transcription - Speech processing"
  },
  {
    "objectID": "notebooks.html#getting-started",
    "href": "notebooks.html#getting-started",
    "title": "Interactive Notebooks",
    "section": "Getting Started",
    "text": "Getting Started\n\nRunning Notebooks\n\nGoogle Colab: Click any notebook link above\nLocal Jupyter: Clone the repository and run jupyter notebook\nBinder: Launch interactive environment (link coming soon)\n\n\n\nPrerequisites\n\nBasic Python knowledge\nFamiliarity with NumPy, Pandas, Matplotlib\nLinear algebra and calculus basics"
  },
  {
    "objectID": "notebooks.html#tips-for-success",
    "href": "notebooks.html#tips-for-success",
    "title": "Interactive Notebooks",
    "section": "Tips for Success",
    "text": "Tips for Success\n\nStart Sequential: Begin with Fundamentals before diving into advanced topics\nPractice Regularly: Code along with each notebook\nExperiment: Modify parameters and observe changes\nVisualize: Pay attention to plots and visual explanations"
  },
  {
    "objectID": "notebooks.html#quick-navigation",
    "href": "notebooks.html#quick-navigation",
    "title": "Interactive Notebooks",
    "section": "Quick Navigation",
    "text": "Quick Navigation\n\nLecture Slides - Theoretical foundations\nCourse Homepage - Main course page\nInstructor - Nipun Batra’s homepage"
  }
]