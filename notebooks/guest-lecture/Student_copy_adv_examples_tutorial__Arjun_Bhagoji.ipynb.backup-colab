{
  "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "---\n",
      "author: Arjun Bhagoji\n",
      "badges: true\n",
      "categories:\n",
      "- ML\n",
      "date: '2024-02-16'\n",
      "title: Adversarial Examples for ML\n",
      "toc: true\n",
      "\n",
      "---\n"
     ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChWyu9ihdYqL"
      },
      "source": [
        "## Data, model and attack utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa7HmicODNB7"
      },
      "source": [
        "The colab environment already has all the necessary Python packages installed. Specifically, we are using *numpy*, *torch* and *torchvision*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhg9RV_Xvb0G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n187K3yxS66v"
      },
      "outputs": [],
      "source": [
        "# Choosing backend\n",
        "if torch.backends.mps.is_available():\n",
        "    device=torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    device=torch.device(\"cuda\")\n",
        "else:\n",
        "    device=torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8cVAqdLFCtp"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmaFq2JwdGeQ"
      },
      "source": [
        "We load in the data using the in-built data loaders in PyTorch. It offers functionality for many commonly used computer vision datasets, but we will just use MNIST (a dataset of black and white handwritten digits) for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lvZtQWtxPsN"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset, data_dir, training_time):\n",
        "    if dataset == 'CIFAR-10':\n",
        "        loader_train, loader_test, data_details = load_cifar_dataset(data_dir, training_time)\n",
        "    elif 'MNIST' in dataset:\n",
        "        loader_train, loader_test, data_details = load_mnist_dataset(data_dir, training_time)\n",
        "    else:\n",
        "        raise ValueError('No support for dataset %s' % args.dataset)\n",
        "\n",
        "    return loader_train, loader_test, data_details\n",
        "\n",
        "\n",
        "def load_mnist_dataset(data_dir, training_time):\n",
        "    # MNIST data loaders\n",
        "    trainset = datasets.MNIST(root=data_dir, train=True,\n",
        "                                download=True, transform=transforms.ToTensor())\n",
        "    testset = datasets.MNIST(root=data_dir, train=False,\n",
        "                                download=True, transform=transforms.ToTensor())\n",
        "\n",
        "    loader_train = torch.utils.data.DataLoader(trainset,\n",
        "                                batch_size=128,\n",
        "                                shuffle=True)\n",
        "\n",
        "    loader_test = torch.utils.data.DataLoader(testset,\n",
        "                                batch_size=128,\n",
        "                                shuffle=False)\n",
        "    data_details = {'n_channels':1, 'h_in':28, 'w_in':28, 'scale':255.0}\n",
        "    return loader_train, loader_test, data_details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvuaXtkNEU9Y"
      },
      "source": [
        "Having defined the data loaders, we now create the data loaders to be used throughout, as well as a dictionary with the details of the dataset, in case we need it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eypv7G0A0cg-"
      },
      "outputs": [],
      "source": [
        "loader_train, loader_test, data_details = load_dataset('MNIST','data',training_time=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E38ReHKGfYV"
      },
      "source": [
        "### Common path and definitions for train/test\n",
        "\n",
        "Since we need the path to the directory where we will storing our models (pre-trained or not), and we also need to instantiate a copy of the model we defined above, we will run the following commands to have everything setup for test/evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6DgNh-cE_9-"
      },
      "source": [
        "### Defining the model\n",
        "\n",
        "We use a 2-layer fully connected network for the experiments in this tutorial. The definition of a 3 layer convolutional neural network is also provided. The former is sufficient for MNIST, but may not be large enough for more complex tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rgWQHQ6S66v"
      },
      "outputs": [],
      "source": [
        "model_name='fcn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW6Z5ZaTxALx"
      },
      "outputs": [],
      "source": [
        "class cnn_3l_bn(nn.Module):\n",
        "    def __init__(self, n_classes=10):\n",
        "        super(cnn_3l_bn, self).__init__()\n",
        "        #in-channels, no. filters, filter size, stride\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(20)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(50)\n",
        "        # Number of neurons in preceding layer, Number in current layer\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Rectified linear unit activation\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class fcn(nn.Module):\n",
        "  def __init__(self, n_classes=10):\n",
        "    super(fcn, self).__init__()\n",
        "    self.fc1 = nn.Linear(784,200)\n",
        "    self.fc2 = nn.Linear(200,200)\n",
        "    self.fc3 = nn.Linear(200,n_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaF4H6AJRi7-"
      },
      "outputs": [],
      "source": [
        "if 'fcn' in model_name:\n",
        "  model_dir_name='models'+'/'+'MNIST'+'/fcn/'\n",
        "  if not os.path.exists(model_dir_name):\n",
        "    os.makedirs(model_dir_name)\n",
        "\n",
        "  # Basic setup\n",
        "  net = fcn(10)\n",
        "elif 'cnn' in model_name:\n",
        "  model_dir_name='models'+'/'+'MNIST'+'/cnn_3l_bn/'\n",
        "  if not os.path.exists(model_dir_name):\n",
        "    os.makedirs(model_dir_name)\n",
        "\n",
        "  # Basic setup\n",
        "  net = cnn_3l_bn(10)\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(reduction='none')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJCBRyQqF2bf"
      },
      "source": [
        "## Training the benign/standard model\n",
        "This is sample code for training your own model. Since it takes time to run, for the purposes of the tutorial, we will assume we already have trained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8sEUkBt31Pl"
      },
      "outputs": [],
      "source": [
        "########################################  Benign/standard training ########################################\n",
        "def train_one_epoch(model, optimizer, loader_train, verbose=True):\n",
        "    losses = []\n",
        "    model.train()\n",
        "    for t, (x, y) in enumerate(loader_train):\n",
        "        x.to(device)\n",
        "        y.to(device)\n",
        "        x_var = Variable(x, requires_grad= True).to(device)\n",
        "        y_var = Variable(y, requires_grad= False).to(device)\n",
        "        scores = model(x_var)\n",
        "        # loss = loss_fn(scores, y_var)\n",
        "        loss_function = nn.CrossEntropyLoss(reduction='none')\n",
        "        batch_loss = loss_function(scores, y_var)\n",
        "        loss = torch.mean(batch_loss)\n",
        "        losses.append(loss.data.cpu().numpy())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # print(model.conv1.weight.grad)\n",
        "        optimizer.step()\n",
        "    if verbose:\n",
        "        print('loss = %.8f' % (loss.data))\n",
        "    return np.mean(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GxJuvOPHQev"
      },
      "source": [
        "### Actual training loop\n",
        "\n",
        "We define the necessary parameters for training (batch size, learning rate etc.), instantiate the optimizer and then train for 50 epochs.\n",
        "\n",
        "In each epoch, the model is trained using all of the training data, which is split into batches of size 128. Thus, one step of the optimizer uses 128 samples, and there are a total of 50*(50,000/128) steps in the entire process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlEaZ-UkoqCe"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "batch_size=128\n",
        "learning_rate=0.1 #\n",
        "weight_decay=2e-4\n",
        "save_checkpoint=True\n",
        "\n",
        "# Torch optimizer\n",
        "optimizer = torch.optim.SGD(net.parameters(),\n",
        "                            lr=learning_rate,\n",
        "                            momentum=0.9,\n",
        "                            weight_decay=weight_decay)\n",
        "\n",
        "# if args.lr_schedule == 'cosine':\n",
        "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "#             T_max=args.train_epochs, eta_min=0, last_epoch=-1)\n",
        "# elif args.lr_schedule == 'linear0':\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100,150,200], gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en9jm3St0pSH"
      },
      "outputs": [],
      "source": [
        "for epoch in range(0, 10):\n",
        "    start_time = time.time()\n",
        "    # lr = update_hyparam(epoch, args)\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    print('Current learning rate: {}'.format(lr))\n",
        "    # if not args.is_adv:\n",
        "    ben_loss = train_one_epoch(net, optimizer,\n",
        "                          loader_train, verbose=False)\n",
        "    print('time_taken for #{} epoch = {:.3f}'.format(epoch+1, time.time()-start_time))\n",
        "    if save_checkpoint:\n",
        "        ckpt_path = 'checkpoint_' + str(0)\n",
        "        torch.save(net.state_dict(), model_dir_name + ckpt_path)\n",
        "    print('Train loss - Ben: %s' %\n",
        "        (ben_loss))\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoNMY6Ki_VkI"
      },
      "source": [
        "## Generating Adversarial Examples\n",
        "We will look at how to generate adversarial examples using the Projected Gradient Descent (PGD) method for the model we have trained and visualize the adversarial examples thus generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USIuFBgHvO8K"
      },
      "outputs": [],
      "source": [
        "# Attack utils\n",
        "\n",
        "# Random initialization within the L2 ball\n",
        "def rand_init_l2(img_variable, eps_max):\n",
        "    random_vec = torch.FloatTensor(*img_variable.shape).normal_(0, 1).to(device)\n",
        "    random_vec_norm = torch.max(\n",
        "               random_vec.view(random_vec.size(0), -1).norm(2, 1), torch.tensor(1e-9).to(device))\n",
        "    random_dir = random_vec/random_vec_norm.view(random_vec.size(0),1,1,1)\n",
        "    random_scale = torch.FloatTensor(img_variable.size(0)).uniform_(0, eps_max).to(device)\n",
        "    random_noise = random_scale.view(random_vec.size(0),1,1,1)*random_dir\n",
        "    img_variable = Variable(img_variable.data + random_noise, requires_grad=True).to(device)\n",
        "\n",
        "    return img_variable\n",
        "\n",
        "# Random initialization within the L_inf ball\n",
        "def rand_init_linf(img_variable, eps_max):\n",
        "    random_noise = torch.FloatTensor(*img_variable.shape).uniform_(-eps_max, eps_max).to(device)\n",
        "    img_variable = Variable(img_variable.data + random_noise, requires_grad=True).to(device)\n",
        "\n",
        "    return img_variable\n",
        "\n",
        "# Tracking the best adversarial examples during the generation process\n",
        "def track_best(blosses, b_adv_x, curr_losses, curr_adv_x):\n",
        "    if blosses is None:\n",
        "        b_adv_x = curr_adv_x.clone().detach()\n",
        "        blosses = curr_losses.clone().detach()\n",
        "    else:\n",
        "        replace = curr_losses < blosses\n",
        "        b_adv_x[replace] = curr_adv_x[replace].clone().detach()\n",
        "        blosses[replace] = curr_losses[replace]\n",
        "\n",
        "    return blosses.to(device), b_adv_x.to(device)\n",
        "\n",
        "# Loss calculation\n",
        "def cal_loss(y_out, y_true, targeted):\n",
        "    losses = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "    losses_cal = losses(y_out, y_true).to(device)\n",
        "    loss_cal = torch.mean(losses_cal).to(device)\n",
        "    if targeted:\n",
        "        return loss_cal, losses_cal\n",
        "    else:\n",
        "        return -1*loss_cal, -1*losses_cal\n",
        "\n",
        "# Generating targets for each adversarial example\n",
        "def generate_target_label_tensor(true_label, n_classes):\n",
        "    t = torch.floor(n_classes*torch.rand(true_label.shape)).type(torch.int64)\n",
        "    m = t == true_label\n",
        "    t[m] = (t[m]+ torch.ceil((n_classes-1)*torch.rand(t[m].shape)).type(torch.int64)) % n_classes\n",
        "    return t.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xFJDMoYY64p"
      },
      "source": [
        "This provides the core loop of the attack algorithm which goes as follows:\n",
        "1. The perturbation is initialized to 0.\n",
        "2. The gradient of the model with respect to the current state of the adversarial example is found.\n",
        "3. The gradient is appropriately normalized and added to the current state of the example\n",
        "4. The complete adversarial example is clipped to lie within the input bounds\n",
        "5. Steps 2,3 and 4 are repeated for a fixed number of steps or until some condition is met"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi3vFxX-vOTN"
      },
      "outputs": [],
      "source": [
        "# Attack code\n",
        "def pgd_attack(model, image_tensor, img_variable, tar_label_variable,\n",
        "               n_steps, eps_max, eps_step, clip_min, clip_max, targeted, rand_init):\n",
        "    \"\"\"\n",
        "    image_tensor: tensor which holds the clean images.\n",
        "    img_variable: Corresponding pytorch variable for image_tensor.\n",
        "    tar_label_variable: Assuming targeted attack, this variable holds the targeted labels.\n",
        "    n_steps: number of attack iterations.\n",
        "    eps_max: maximum l_inf attack perturbations.\n",
        "    eps_step: l_inf attack perturbation per step\n",
        "    \"\"\"\n",
        "\n",
        "    best_losses = None\n",
        "    best_adv_x = None\n",
        "    image_tensor = image_tensor.to(device)\n",
        "\n",
        "    if rand_init:\n",
        "        img_variable = rand_init_linf(img_variable, eps_max)\n",
        "\n",
        "    output = model.forward(img_variable)\n",
        "    for i in range(n_steps):\n",
        "        if img_variable.grad is not None:\n",
        "            img_variable.grad.zero_()\n",
        "        output = model.forward(img_variable)\n",
        "        loss_cal, losses_cal = cal_loss(output, tar_label_variable, targeted)\n",
        "        best_losses, best_adv_x = track_best(best_losses, best_adv_x, losses_cal, img_variable)\n",
        "\n",
        "        loss_cal, losses_cal = cal_loss(output, tar_label_variable, targeted)\n",
        "        loss_cal.backward()\n",
        "        # Finding the gradient of the loss\n",
        "        x_grad = -1 * eps_step * torch.sign(img_variable.grad.data)\n",
        "        # Adding gradient to current state of the example\n",
        "        adv_temp = img_variable.data + x_grad\n",
        "        total_grad = adv_temp - image_tensor\n",
        "        total_grad = torch.clamp(total_grad, -eps_max, eps_max)\n",
        "        x_adv = image_tensor + total_grad\n",
        "        # Projecting adversarial example back onto the constraint set\n",
        "        x_adv = torch.clamp(torch.clamp(\n",
        "            x_adv-image_tensor, -1*eps_max, eps_max)+image_tensor, clip_min, clip_max)\n",
        "        img_variable.data = x_adv\n",
        "\n",
        "    best_losses, best_adv_x = track_best(best_losses, best_adv_x, losses_cal, img_variable)\n",
        "\n",
        "    return best_adv_x\n",
        "\n",
        "def pgd_l2_attack(model, image_tensor, img_variable, tar_label_variable,\n",
        "               n_steps, eps_max, eps_step, clip_min, clip_max, targeted,\n",
        "               rand_init, num_restarts):\n",
        "    \"\"\"\n",
        "    image_tensor: tensor which holds the clean images.\n",
        "    img_variable: Corresponding pytorch variable for image_tensor.\n",
        "    tar_label_variable: Assuming targeted attack, this variable holds the targeted labels.\n",
        "    n_steps: number of attack iterations.\n",
        "    eps_max: maximum l_inf attack perturbations.\n",
        "    eps_step: l_inf attack perturbation per step\n",
        "    \"\"\"\n",
        "\n",
        "    best_losses = None\n",
        "    best_adv_x = None\n",
        "    image_tensor_orig = image_tensor.clone().detach()\n",
        "    tar_label_orig = tar_label_variable.clone().detach()\n",
        "\n",
        "    for j in range(num_restarts):\n",
        "        if rand_init:\n",
        "            img_variable = rand_init_l2(img_variable, eps_max)\n",
        "\n",
        "        output = model.forward(img_variable)\n",
        "        for i in range(n_steps):\n",
        "            if img_variable.grad is not None:\n",
        "                img_variable.grad.zero_()\n",
        "            output = model.forward(img_variable)\n",
        "            loss_cal, losses_cal = cal_loss(output, tar_label_variable, targeted)\n",
        "            best_losses, best_adv_x = track_best(best_losses, best_adv_x, losses_cal, img_variable)\n",
        "            loss_cal.backward()\n",
        "            raw_grad = img_variable.grad.data\n",
        "            grad_norm = torch.max(\n",
        "                   raw_grad.view(raw_grad.size(0), -1).norm(2, 1), torch.tensor(1e-9))\n",
        "            grad_dir = raw_grad/grad_norm.view(raw_grad.size(0),1,1,1)\n",
        "            adv_temp = img_variable.data +  -1 * eps_step * grad_dir\n",
        "            # Clipping total perturbation\n",
        "            total_grad = adv_temp - image_tensor\n",
        "            total_grad_norm = torch.max(\n",
        "                   total_grad.view(total_grad.size(0), -1).norm(2, 1), torch.tensor(1e-9))\n",
        "            total_grad_dir = total_grad/total_grad_norm.view(total_grad.size(0),1,1,1)\n",
        "            total_grad_norm_rescale = torch.min(total_grad_norm, torch.tensor(eps_max))\n",
        "            clipped_grad = total_grad_norm_rescale.view(total_grad.size(0),1,1,1) * total_grad_dir\n",
        "            x_adv = image_tensor + clipped_grad\n",
        "            x_adv = torch.clamp(x_adv, clip_min, clip_max)\n",
        "            img_variable.data = x_adv\n",
        "\n",
        "        best_losses, best_adv_x = track_best(best_losses, best_adv_x, losses_cal, img_variable)\n",
        "\n",
        "        diff_array = np.array(x_adv.cpu())-np.array(image_tensor.data.cpu())\n",
        "        diff_array = diff_array.reshape(len(diff_array),-1)\n",
        "\n",
        "        img_variable.data = image_tensor_orig\n",
        "\n",
        "    return best_adv_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh4DcL1yZ1SO"
      },
      "source": [
        "Now we can call the core adversarial example generation function over our data and model to determine how robust the model actually is!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXKJ14A1rj99"
      },
      "outputs": [],
      "source": [
        "def robust_test(model, loss_fn, loader, att_dir, n_batches=0, train_data=False,\n",
        "                training_time=False):\n",
        "    \"\"\"\n",
        "    n_batches (int): Number of batches for evaluation.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    num_correct, num_correct_adv, num_samples = 0, 0, 0\n",
        "    steps = 1\n",
        "    losses_adv = []\n",
        "    losses_ben = []\n",
        "    adv_images = []\n",
        "    adv_labels = []\n",
        "    clean_images = []\n",
        "    correct_labels = []\n",
        "\n",
        "    for t, (x, y) in enumerate(loader):\n",
        "        x=x.to(device)\n",
        "        y=y.to(device)\n",
        "        x_var = Variable(x, requires_grad= True).to(device)\n",
        "        y_var = Variable(y, requires_grad=False).to(device)\n",
        "        if att_dir['targeted']:\n",
        "            y_target = generate_target_label_tensor(\n",
        "                               y_var.cpu(), 10).to(device)\n",
        "        else:\n",
        "            y_target = y_var\n",
        "        if 'PGD_linf' in att_dir['attack']:\n",
        "            adv_x = pgd_attack(model, x, x_var, y_target, att_dir['attack_iter'],\n",
        "                           att_dir['epsilon'], att_dir['eps_step'], att_dir['clip_min'],\n",
        "                           att_dir['clip_max'], att_dir['targeted'], att_dir['rand_init'])\n",
        "        elif 'PGD_l2' in att_dir['attack']:\n",
        "            adv_x = pgd_l2_attack(model, x, x_var, y_target, att_dir['attack_iter'],\n",
        "                           att_dir['epsilon'], att_dir['eps_step'], att_dir['clip_min'],\n",
        "                           att_dir['clip_max'], att_dir['targeted'], att_dir['rand_init'],\n",
        "                           att_dir['num_restarts'])\n",
        "        # Predictions\n",
        "        # scores = model(x.cuda())\n",
        "        scores = model(x)\n",
        "        _, preds = scores.data.max(1)\n",
        "        scores_adv = model(adv_x)\n",
        "        _, preds_adv = scores_adv.data.max(1)\n",
        "        # Losses\n",
        "        batch_loss_adv = loss_fn(scores_adv, y)\n",
        "        loss_adv = torch.mean(batch_loss_adv)\n",
        "        losses_adv.append(loss_adv.data.cpu().numpy())\n",
        "        batch_loss_ben = loss_fn(scores, y)\n",
        "        loss_ben = torch.mean(batch_loss_ben)\n",
        "        losses_ben.append(loss_ben.data.cpu().numpy())\n",
        "        # Correct count\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_correct_adv += (preds_adv == y).sum()\n",
        "        num_samples += len(preds)\n",
        "        # Adding images and labels to list\n",
        "        adv_images.extend(adv_x)\n",
        "        adv_labels.extend(preds_adv)\n",
        "        clean_images.extend(x)\n",
        "        correct_labels.extend(preds)\n",
        "\n",
        "        if n_batches > 0 and steps==n_batches:\n",
        "            break\n",
        "        steps += 1\n",
        "\n",
        "    acc = float(num_correct) / num_samples\n",
        "    acc_adv = float(num_correct_adv) / num_samples\n",
        "    print('Clean accuracy: {:.2f}% ({}/{})'.format(\n",
        "        100.*acc,\n",
        "        num_correct,\n",
        "        num_samples,\n",
        "    ))\n",
        "    print('Adversarial accuracy: {:.2f}% ({}/{})'.format(\n",
        "        100.*acc_adv,\n",
        "        num_correct_adv,\n",
        "        num_samples,\n",
        "    ))\n",
        "\n",
        "    return 100.*acc, 100.*acc_adv, np.mean(losses_ben), np.mean(losses_adv), adv_images, adv_labels, clean_images, correct_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvE62Xo2aB3L"
      },
      "source": [
        "The most important parameters below are epsilon (which controls the magnitude of the perturbation), gamma (which determines how far outside the constraint set intial search is allowed) and attack_iter (which is just the number of attack iterations)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3SCANRgthHc"
      },
      "outputs": [],
      "source": [
        "# Attack setup\n",
        "gamma=2.5\n",
        "epsilon=0.2\n",
        "attack_iter=10\n",
        "delta=epsilon*gamma/attack_iter\n",
        "attack_params = {'attack': 'PGD_linf', 'epsilon': epsilon,\n",
        "              'attack_iter': 10, 'eps_step': delta,\n",
        "              'targeted': True, 'clip_min': 0.0,\n",
        "              'clip_max': 1.0,'rand_init': True,\n",
        "              'num_restarts': 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXVF3fnUh-MD"
      },
      "source": [
        "Now, we load the model (**remember to first upload it into the models folder!**) and then generate adversarial examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCenf5iq_znI"
      },
      "outputs": [],
      "source": [
        "ckpt_path = 'checkpoint_' + str(0)\n",
        "net.to(device)\n",
        "net.eval()\n",
        "net.load_state_dict(torch.load(model_dir_name + ckpt_path, map_location=device))\n",
        "n_batches_eval = 10\n",
        "print('Test set validation')\n",
        "# Running validation\n",
        "acc_test, acc_adv_test, test_loss, test_loss_adv, adv_images, adv_labels, clean_images, correct_labels = robust_test(net,\n",
        "    criterion, loader_test, attack_params, n_batches=n_batches_eval,\n",
        "    train_data=False, training_time=True)\n",
        "# print('Training set validation')\n",
        "# acc_train, acc_adv_train, train_loss, train_loss_adv, _ = robust_test(net,\n",
        "#     criterion, loader_train_all, args, attack_params, n_batches=n_batches_eval,\n",
        "#     train_data=True, training_time=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG-nXfIs7JjQ"
      },
      "source": [
        "### Visualizing the adversarial examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ueyWUdmeYYN"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(9, 13))\n",
        "columns = 4\n",
        "rows = 5\n",
        "\n",
        "# ax enables access to manipulate each of subplots\n",
        "ax = []\n",
        "\n",
        "for i in range(columns*rows):\n",
        "    image_count=int(i/2)\n",
        "    if i%2==1:\n",
        "      img = adv_images[image_count].reshape(28,28).cpu()\n",
        "      # create subplot and append to ax\n",
        "      ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "      ax[-1].set_title(\"output:\"+str(adv_labels[image_count].cpu().numpy()))  # set title\n",
        "      ax[-1].set_xticks([])\n",
        "      ax[-1].set_yticks([])\n",
        "    else:\n",
        "      img = clean_images[image_count].reshape(28,28).cpu()\n",
        "      # create subplot and append to ax\n",
        "      ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "      ax[-1].set_title(\"output:\"+str(correct_labels[image_count].cpu().numpy()))  # set title\n",
        "      ax[-1].set_xticks([])\n",
        "      ax[-1].set_yticks([])\n",
        "    plt.imshow(img, interpolation='nearest',cmap='gray')\n",
        "\n",
        "\n",
        "plt.show()  # finally, render the plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zscMzWF5IWIT"
      },
      "source": [
        "## Training robust models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Izznw9iacbC"
      },
      "source": [
        "This training loop is very similar to the benign one, except that we now call the adversarial example generation function to generate adversarial examples during the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frO5g0M4I0u8"
      },
      "outputs": [],
      "source": [
        "########################################  Adversarial training ########################################\n",
        "def robust_train_one_epoch(model, optimizer, loader_train, att_dir,\n",
        "                           epoch):\n",
        "    # print('Current eps: {}, delta: {}'.format(eps, delta))\n",
        "    losses_adv = []\n",
        "    losses_ben = []\n",
        "    model.train()\n",
        "    for t, (x, y) in enumerate(loader_train):\n",
        "        x=x.to(device)\n",
        "        y=y.to(device)\n",
        "        x_var = Variable(x, requires_grad= True)\n",
        "        y_var = Variable(y, requires_grad= False)\n",
        "        if att_dir['targeted']:\n",
        "            y_target = generate_target_label_tensor(\n",
        "                               y_var.cpu(), 10).to(device)\n",
        "        else:\n",
        "            y_target = y_var\n",
        "        if 'PGD_linf' in att_dir['attack']:\n",
        "            adv_x = pgd_attack(model, x, x_var, y_target, att_dir['attack_iter'],\n",
        "                           att_dir['epsilon'], att_dir['eps_step'], att_dir['clip_min'],\n",
        "                           att_dir['clip_max'], att_dir['targeted'], att_dir['rand_init'])\n",
        "        elif 'PGD_l2' in att_dir['attack']:\n",
        "            adv_x = pgd_l2_attack(model, x, x_var, y_target, att_dir['attack_iter'],\n",
        "                           att_dir['epsilon'], att_dir['eps_step'], att_dir['clip_min'],\n",
        "                           att_dir['clip_max'], att_dir['targeted'], att_dir['rand_init'],\n",
        "                           att_dir['num_restarts'])\n",
        "        scores = model(adv_x)\n",
        "        loss_function = nn.CrossEntropyLoss(reduction='none')\n",
        "        batch_loss_adv = loss_function(scores, y_var)\n",
        "        batch_loss_ben = loss_function(model(x),y_var)\n",
        "        loss = torch.mean(batch_loss_adv)\n",
        "        loss_ben = torch.mean(batch_loss_ben)\n",
        "        losses_ben.append(loss_ben.data.cpu().numpy())\n",
        "        losses_adv.append(loss.data.cpu().numpy())\n",
        "        # GD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # print(model.conv1.weight.grad)\n",
        "        optimizer.step()\n",
        "    return np.mean(losses_adv), np.mean(losses_ben)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Egh5VtIfnu"
      },
      "outputs": [],
      "source": [
        "for epoch in range(0, 10):\n",
        "    start_time = time.time()\n",
        "    # lr = update_hyparam(epoch, args)\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    print('Current learning rate: {}'.format(lr))\n",
        "    curr_loss, ben_loss = robust_train_one_epoch(net,\n",
        "                            optimizer, loader_train, attack_params,\n",
        "                            epoch)\n",
        "    print('time_taken for #{} epoch = {:.3f}'.format(epoch+1, time.time()-start_time))\n",
        "    if save_checkpoint:\n",
        "        ckpt_path = 'checkpoint_adv' + str(0)\n",
        "        torch.save(net.state_dict(), model_dir_name + ckpt_path)\n",
        "    print('Train loss - Ben: %s, Adv: %s' %\n",
        "        (ben_loss, curr_loss))\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqZba86IsIMZ"
      },
      "source": [
        "## Evaluating the robust model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE9Yl0Dia7bW"
      },
      "source": [
        "Evaluating the robust model, we find its accuracy on adversarial examples has increased significantly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4jm8hemr-pz"
      },
      "outputs": [],
      "source": [
        "ckpt_path = 'checkpoint_adv' + str(0)\n",
        "net.eval()\n",
        "net.load_state_dict(torch.load(model_dir_name + ckpt_path, map_location=device))\n",
        "n_batches_eval = 10\n",
        "print('Test set validation')\n",
        "# Running validation\n",
        "acc_test_r, acc_adv_test_r, test_loss_r, test_loss_adv_r, adv_images_r, adv_labels_r, clean_images_r, correct_labels_r = robust_test(net,\n",
        "    criterion, loader_test, attack_params, n_batches=n_batches_eval,\n",
        "    train_data=False, training_time=True)\n",
        "# print('Training set validation')\n",
        "# acc_train, acc_adv_train, train_loss, train_loss_adv, _ = robust_test(net,\n",
        "#     criterion, loader_train_all, args, attack_params, n_batches=n_batches_eval,\n",
        "#     train_data=True, training_time=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-pvTVjvklmH"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(9, 13))\n",
        "columns = 4\n",
        "rows = 5\n",
        "\n",
        "# ax enables access to manipulate each of subplots\n",
        "ax = []\n",
        "\n",
        "for i in range(columns*rows):\n",
        "    image_count=int(i/2)\n",
        "    if i%2==1:\n",
        "      img = adv_images_r[image_count].reshape(28,28).cpu()\n",
        "      # create subplot and append to ax\n",
        "      ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "      ax[-1].set_title(\"output:\"+str(adv_labels_r[image_count].cpu().numpy()))  # set title\n",
        "      ax[-1].set_xticks([])\n",
        "      ax[-1].set_yticks([])\n",
        "    else:\n",
        "      img = clean_images_r[image_count].reshape(28,28).cpu()\n",
        "      # create subplot and append to ax\n",
        "      ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "      ax[-1].set_title(\"output:\"+str(correct_labels_r[image_count].cpu().numpy()))  # set title\n",
        "      ax[-1].set_xticks([])\n",
        "      ax[-1].set_yticks([])\n",
        "    plt.imshow(img, interpolation='nearest',cmap='gray')\n",
        "\n",
        "\n",
        "plt.show()  # finally, render the plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBRAa2b0bKT7"
      },
      "source": [
        "## Discussion questions\n",
        "1. Doesn't robust training solve the problem of adversarial examples? Why is there still so much research on the topic?\n",
        "2. How would a real-world attacker try to carry out this attack *without* access to the classifier being used?\n",
        "3. What does the existence of adversarial examples tell us about modern ML models?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcNJZEKLbNP5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
